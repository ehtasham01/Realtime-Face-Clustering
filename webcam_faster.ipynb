{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import FileVideoStream\n",
    "from imutils.video import VideoStream\n",
    "from sklearn.cluster import DBSCAN\n",
    "from imutils.video import FPS\n",
    "from imutils import paths\n",
    "import dlib.cuda as cuda\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceClusteringAgent:\n",
    "    \"\"\"DBSCAN based Blustering\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.known = dict()\n",
    "        self.unknown = dict()\n",
    "        self.noise = dict()\n",
    "        \n",
    "    def predict(self, new_encoding):\n",
    "        label = -1\n",
    "        encoding_dict = self.unknown\n",
    "        \n",
    "        if not encoding_dict:\n",
    "            encoding_dict[len(encoding_dict)] = [new_encoding]\n",
    "\n",
    "        else:\n",
    "            for id in encoding_dict:\n",
    "                known_encodings = encoding_dict[id] \n",
    "                results = face_recognition.compare_faces(known_encodings, new_encoding)\n",
    "                if all(results):\n",
    "                    encoding_dict[id] += [new_encoding]\n",
    "                    label = id\n",
    "            if(label == -1): \n",
    "                encoding_dict[len(encoding_dict)] = [new_encoding]            \n",
    "            \n",
    "        return label\n",
    "        \n",
    "    def fit(self, new_encoding):\n",
    "        return self.predict(new_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(fca):\n",
    "    \n",
    "    print(\"[INFO] starting video stream...\")\n",
    "    vs = VideoStream(src=0).start()\n",
    "    time.sleep(2.0)\n",
    "    fps = FPS().start()\n",
    "\n",
    "\n",
    "    while True:\n",
    "        # getFrame\n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=500)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        boxes = face_recognition.face_locations(rgb,model=\"cnn\")\n",
    "\n",
    "        # compute the facial embedding for the face\n",
    "        ids = []\n",
    "        new_encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "        if new_encodings:\n",
    "            for new_encoding in new_encodings:\n",
    "                ids.append(fca.fit(new_encoding))\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "                # coordinates\n",
    "                (top, right, bottom, left) = box\n",
    "                y = top - 10 if top - 10 > 10 else top + 10\n",
    "\n",
    "                # perform classification to recognize the face\n",
    "                name = \"ID\"\n",
    "                text = \"{}: {}\".format(name, ids[i])\n",
    "\n",
    "                # plot at image\n",
    "                cv2.rectangle(frame, (right,top), (left, bottom), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, text, (left, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 200), 2)\n",
    "\n",
    "#         cv2.putText(frame, 'Counting: {}'.format(len(labelSet)), (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 100, 200), 2)\n",
    "\n",
    "        \n",
    "        # update the FPS counter\n",
    "        fps.update()\n",
    "\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    # stop the timer and display FPS information\n",
    "    fps.stop()\n",
    "    print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "    # do a bit of cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "    vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting video stream...\n",
      "[INFO] elasped time: 39.41\n",
      "[INFO] approx. FPS: 12.74\n"
     ]
    }
   ],
   "source": [
    "fca = FaceClusteringAgent()\n",
    "main(fca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
